#######################################
# KAFKA - INSTALACIÓN Y CONFIGURACIÓN #
#######################################


1. INSTALACIÓN
2. CONFIGURACIÓN
3. COSAS PENDIENTES

-----------------------------------------------------------------------------------------------------------------------------

1. INSTALACIÓN

Los pasos indicados a continuación deben realizarse en todos y cada uno de los nodos que vayan a conformar el cluster de Kafka:

- Subir el software a /var/tmp:
  # md5sum /var/tmp/kafka_2.11-1.0.0.tgz
  b652611004a992cd71f13b1dfe304b55  /var/tmp/kafka_2.11-1.0.0.tgz

- Ubicar el software en /opt y desplegar:
  # mv /var/tmp/kafka_2.11-1.0.0.tgz /opt
  # cd /opt
  # tar xvfz kafka_2.11-1.0.0.tgz
  # rm /opt/kafka_2.11-1.0.0.tgz

- Crear enlace simbólico para ubicar los logs en la partición deseada:
  # mkdir /var/log/kafka
  # cd /opt/kafka_2.11-1.0.0
  # rm -fr logs/
  # ln -s /var/log/kafka logs
  # ls -rtl logs

- Crear enlace simbólico para acceder a la configuración vía /etc:
  # cd /etc
  # ln -s /opt/kafka_2.11-1.0.0/config kafka
  # ls -rtl kafka

- Añadir los comandos de Kafka a la variable PATH:
  # view .bash_profile
  ...
  # Kafka PATH
  PATH=$PATH:/opt/kafka_2.11-1.0.0/bin
  export PATH

-----------------------------------------------------------------------------------------------------------------------------

2. CONFIGURACIÓN

- Analizar el disco disponible y definir la estrategia de ubicación de los topics, asi como la retención de los datos:

  TIPO DISCO      PUNTO MONTAJE       DISCO DISPONIBLE PARA KAFKA
  --------------------------------------------------------------------------
  SAS 15K         /var/lib/data        400 GB x6 =  2400 GB
  SATA SSD        /var/lib/data_ssd   1840 GB x6 = 11040 GB <- Usaremos este
  --------------------------------------------------------------------------
                                    
  TOPIC               PUERTO  UBICACIÓN                           DISCO TOTAL     REPLICACION     DISCO EFECTIVO
  --------------------------------------------------------------------------------------------------------------
  raw_logs            9092    /var/lib/data_ssd/kafka             1000 GB         factor 2        2000 GB
  beautified_logs     9092    /var/lib/data_ssd/kafka             4400 GB         factor 2        8800 GB
  aggregated_metrics  9092    /var/lib/data_ssd/kafka              100 GB         factor 2         200 GB
  control_flow        9092    /var/lib/data_sdd/kafka              500 MB         factor 2           1 GB
  --------------------------------------------------------------------------------------------------------------

- Crear la ubicación de los datos de los topics:
  # mkdir /var/lib/data_ssd/kafka
 
- Configurar el Broker:
  # view /etc/kafka/server.properties
  ...
  broker.id=1
  listeners=PLAINTEXT://:9092
  log.dirs=/var/lib/data_ssd/kafka
  num.partitions=6
  offsets.topic.replication.factor=2
  transaction.state.log.replication.factor=2
  transaction.state.log.min.isr=2
  zookeeper.connect=node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181,node7:2181
  group.initial.rebalance.delay.ms=3
  ...
  (cada nodo tiene que tener un broker.id único por cada Broker)

- Arrancar los Broker de Kafka:
  # kafka-server-start.sh -daemon /etc/kafka/server.properties
  # jps

- Arrancar un Topic de prueba:
  # kafka-topics.sh --create --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=1073741824000 --topic raw_logs
  # kafka-topics.sh --create --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=4724464025600 --topic beautified_logs
  # kafka-topics.sh --create --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=107374182400 --topic aggregated_metrics
  # kafka-topics.sh --create --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=524288000 --topic control_flow

- Comprobar la correcta creación de los Topics:
  # kafka-topics.sh --list --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181
  aggregated_metrics
  beautified_logs
  control_flow
  raw_logs

  # kafka-topics.sh --describe --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181
  Topic:aggregated_metrics        PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=107374182400
          Topic: aggregated_metrics       Partition: 0    Leader: 5       Replicas: 5,3   Isr: 5,3
          Topic: aggregated_metrics       Partition: 1    Leader: 6       Replicas: 6,4   Isr: 6,4
          Topic: aggregated_metrics       Partition: 2    Leader: 1       Replicas: 1,5   Isr: 1,5
          Topic: aggregated_metrics       Partition: 3    Leader: 2       Replicas: 2,6   Isr: 2,6
          Topic: aggregated_metrics       Partition: 4    Leader: 3       Replicas: 3,1   Isr: 3,1
          Topic: aggregated_metrics       Partition: 5    Leader: 4       Replicas: 4,2   Isr: 4,2
  Topic:beautified_logs   PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=4724464025600
          Topic: beautified_logs  Partition: 0    Leader: 4       Replicas: 4,6   Isr: 4,6
          Topic: beautified_logs  Partition: 1    Leader: 5       Replicas: 5,1   Isr: 5,1
          Topic: beautified_logs  Partition: 2    Leader: 6       Replicas: 6,2   Isr: 6,2
          Topic: beautified_logs  Partition: 3    Leader: 1       Replicas: 1,3   Isr: 1,3
          Topic: beautified_logs  Partition: 4    Leader: 2       Replicas: 2,4   Isr: 2,4
          Topic: beautified_logs  Partition: 5    Leader: 3       Replicas: 3,5   Isr: 3,5
  Topic:control_flow      PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=524288000
          Topic: control_flow     Partition: 0    Leader: 2       Replicas: 2,4   Isr: 2,4
          Topic: control_flow     Partition: 1    Leader: 3       Replicas: 3,5   Isr: 3,5
          Topic: control_flow     Partition: 2    Leader: 4       Replicas: 4,6   Isr: 4,6
          Topic: control_flow     Partition: 3    Leader: 5       Replicas: 5,1   Isr: 5,1
          Topic: control_flow     Partition: 4    Leader: 6       Replicas: 6,2   Isr: 6,2
          Topic: control_flow     Partition: 5    Leader: 1       Replicas: 1,3   Isr: 1,3
  Topic:raw_logs  PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=1073741824000
          Topic: raw_logs Partition: 0    Leader: 5       Replicas: 5,4   Isr: 5,4
          Topic: raw_logs Partition: 1    Leader: 6       Replicas: 6,5   Isr: 6,5
          Topic: raw_logs Partition: 2    Leader: 1       Replicas: 1,6   Isr: 1,6
          Topic: raw_logs Partition: 3    Leader: 2       Replicas: 2,1   Isr: 2,1
          Topic: raw_logs Partition: 4    Leader: 3       Replicas: 3,2   Isr: 3,2
          Topic: raw_logs Partition: 5    Leader: 4       Replicas: 4,3   Isr: 4,3

- Crear un Productor y volcar su salida al Topic de prueba:
  # kafka-console-producer.sh --broker-list node1:9092,node2:9092,node3:9092,node4:9092,node5:9092,node6:9092 --topic raw_logs

- Crear un Consumidor y leer el contenido del Topic de prueba:
  # kafka-console-consumer.sh --zookeeper node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181 --from-beginning --topic raw_logs

-----------------------------------------------------------------------------------------------------------------------------

3. COSAS PENDIENTES

- Configurar rotado y retención de los logs del propio Kafka
- Configurar el Broker de Kafka como un servicio.
- Hacer correr los procesos o servicio de Kafka con un usuario propio.
- Identificar las comunicaciones internas entre nodos y con otros sistemas (ZooKeeper, Flink y Logstash), habilitar el servicio firewalld y configurar las correspondientes reglas.


